# trigger_training.yaml
# 从账号B (de2025-475823) 触发账号A (pelagic-pager-472017-v5) 的Vertex AI Pipeline训练

steps:
  # 提交Vertex AI Pipeline Job到账号A
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk:latest'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        set -e
        
        # ===========================================
        # 配置参数
        # ===========================================
        ACCOUNT_A_PROJECT="pelagic-pager-472017-v5"
        REGION="us-central1"
        PIPELINE_ROOT="gs://temp2_de2025_group6"
        PIPELINE_YAML="${PIPELINE_ROOT}/heart_disease_training_pipeline.yaml"
        
        # Pipeline参数
        DATA_BUCKET="data2_de2025_group6"
        MODEL_BUCKET="models2_de2025_group6"
        TRAINSET_FILE="Heart_disease_cleveland_new.csv"
        
        # ===========================================
        # 显示配置信息
        # ===========================================
        echo "=========================================="
        echo "🚀 触发账号A的Vertex AI Pipeline训练"
        echo "=========================================="
        echo "目标项目: $ACCOUNT_A_PROJECT"
        echo "Region: $REGION"
        echo "Pipeline Root: $PIPELINE_ROOT"
        echo "Pipeline YAML: $PIPELINE_YAML"
        echo "数据bucket: $DATA_BUCKET"
        echo "模型bucket: $MODEL_BUCKET"
        echo "=========================================="
        
        # ===========================================
        # 安装Python依赖
        # ===========================================
        echo "📦 安装必要的Python包..."
        pip3 install --quiet google-cloud-aiplatform kfp
        
        # ===========================================
        # 使用Python提交Pipeline
        # ===========================================
        echo "📤 正在提交Pipeline Job..."
        
        python3 << 'EOF'
import google.cloud.aiplatform as aip
from datetime import datetime

# 初始化Vertex AI
aip.init(
    project="pelagic-pager-472017-v5",
    location="us-central1",
)

# 生成唯一的job名称
job_name = f"heart-disease-training-{datetime.now().strftime('%Y%m%d-%H%M%S')}"

# 创建Pipeline Job
job = aip.PipelineJob(
    display_name=job_name,
    template_path="gs://temp2_de2025_group6/heart_disease_training_pipeline.yaml",
    pipeline_root="gs://temp2_de2025_group6",
    parameter_values={
        'project_id': 'pelagic-pager-472017-v5',
        'data_bucket': 'data2_de2025_group6',
        'trainset_filename': 'Heart_disease_cleveland_new.csv',
        'model_repo': 'models2_de2025_group6'
    },
    enable_caching=False,
)

# 提交job (异步)
job.submit()

print(f"✅ Pipeline Job已提交!")
print(f"Job名称: {job_name}")
print(f"Job资源: {job.resource_name}")
print(f"查看进度: https://console.cloud.google.com/vertex-ai/pipelines?project=pelagic-pager-472017-v5")
EOF
        
        echo ""
        echo "=========================================="
        echo "✅ 触发成功!"
        echo "=========================================="

timeout: 1200s  # 20分钟超时

options:
  logging: CLOUD_LOGGING_ONLY
  machineType: 'E2_HIGHCPU_8'